<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Numerical Analysis | Marcos M. Raimundo</title>
    <link>http://localhost:1313/mraimundo/tag/numerical-analysis/</link>
      <atom:link href="http://localhost:1313/mraimundo/tag/numerical-analysis/index.xml" rel="self" type="application/rss+xml" />
    <description>Numerical Analysis</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Sun, 05 Jan 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/mraimundo/media/icon_hu_ff945c07853dd4a6.png</url>
      <title>Numerical Analysis</title>
      <link>http://localhost:1313/mraimundo/tag/numerical-analysis/</link>
    </image>
    
    <item>
      <title>Gradient-based Algorithms for Multi-objective Optimization</title>
      <link>http://localhost:1313/mraimundo/projects/mol/</link>
      <pubDate>Sun, 05 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/mraimundo/projects/mol/</guid>
      <description>&lt;p&gt;This project addresses the fundamental mathematical challenge of optimizing vector-valued functions without reducing them to a single scalar objective a priori. The core research question is: &lt;strong&gt;how do we define and efficiently follow a descent direction when objectives conflict?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;While scalar optimization relies on setting the gradient to zero, multi-objective optimization operates under the &lt;strong&gt;Karush-Kuhn-Tucker (KKT)&lt;/strong&gt; conditions for Pareto optimality. Our research focuses on developing rigorous, efficient algorithms to reach these stationary points in continuous, differentiable spaces.&lt;/p&gt;
&lt;h3 id=&#34;key-research-topics&#34;&gt;Key Research Topics:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Descent Directions:&lt;/strong&gt; Developing algorithms that extend the concepts of Steepest Descent and Newton&amp;rsquo;s method to multiple objectives, solving the quadratic subproblems required to find common descent vectors.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bilevel Optimization:&lt;/strong&gt; Investigating theoretical properties and solvers for hierarchical problems (Stackelberg games), where one optimization problem is embedded within the constraints of another.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pareto Front Approximation:&lt;/strong&gt; Creating methods to efficiently map the continuous manifold of optimal solutions, rather than finding just a single point.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JAX Implementation:&lt;/strong&gt; Leveraging Just-In-Time (JIT) compilation and automatic differentiation to implement these mathematical concepts in the &lt;strong&gt;&lt;code&gt;jaxmoo&lt;/code&gt;&lt;/strong&gt; library, providing a low-level, high-performance foundation for researchers.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Gradient-based Algorithms for Multi-objective Optimization</title>
      <link>http://localhost:1313/mraimundo/projects/moo/</link>
      <pubDate>Sun, 05 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/mraimundo/projects/moo/</guid>
      <description>&lt;p&gt;This project addresses the fundamental mathematical challenge of optimizing vector-valued functions without reducing them to a single scalar objective a priori. The core research question is: &lt;strong&gt;how do we define and efficiently follow a descent direction when objectives conflict?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;While scalar optimization relies on setting the gradient to zero, multi-objective optimization operates under the &lt;strong&gt;Karush-Kuhn-Tucker (KKT)&lt;/strong&gt; conditions for Pareto optimality. Our research focuses on developing rigorous, efficient algorithms to reach these stationary points in continuous, differentiable spaces.&lt;/p&gt;
&lt;h3 id=&#34;key-research-topics&#34;&gt;Key Research Topics:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Descent Directions:&lt;/strong&gt; Developing algorithms that extend the concepts of Steepest Descent and Newton&amp;rsquo;s method to multiple objectives, solving the quadratic subproblems required to find common descent vectors.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bilevel Optimization:&lt;/strong&gt; Investigating theoretical properties and solvers for hierarchical problems (Stackelberg games), where one optimization problem is embedded within the constraints of another.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pareto Front Approximation:&lt;/strong&gt; Creating methods to efficiently map the continuous manifold of optimal solutions, rather than finding just a single point.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JAX Implementation:&lt;/strong&gt; Leveraging Just-In-Time (JIT) compilation and automatic differentiation to implement these mathematical concepts in the &lt;strong&gt;&lt;code&gt;jaxmoo&lt;/code&gt;&lt;/strong&gt; library, providing a low-level, high-performance foundation for researchers.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
